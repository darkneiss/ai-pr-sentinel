# Local runtime example.
# CI/CD deploy uses `.env.template` rendered by `.github/workflows/deploy-runtime.yml`.

# Runtime image published by CI/CD (GHCR, ECR, etc.)
# Example:
# API_IMAGE=ghcr.io/example-org/ai-pr-sentinel-api:v1.2.3
API_IMAGE=ghcr.io/example-org/ai-pr-sentinel-api:latest

# Public FQDN that resolves to the server static IP (A record)
# Example development:
# SERVER_NAME=development.env.example.com
# Example production:
# SERVER_NAME=api.example.com
SERVER_NAME=development.env.example.com

# API listen port (used by both API process and docker-compose upstream wiring)
API_PORT=3000

# Enable automatic certificate issuance + TLS startup.
# Set to false only for local testing without public DNS.
NGINX_TLS_ENABLED=true

# Contact email used by Let's Encrypt / certbot
LETSENCRYPT_EMAIL=ops@example.com

# Use Let's Encrypt staging for tests to avoid production rate limits.
CERTBOT_STAGING=false

# Renewal loop interval for certbot sidecar.
CERTBOT_RENEW_INTERVAL_SECONDS=43200

# Nginx runtime hardening defaults
NGINX_CLIENT_MAX_BODY_SIZE=100m
NGINX_KEEPALIVE_TIMEOUT=5s
NGINX_CLIENT_BODY_TIMEOUT=10s
NGINX_CLIENT_HEADER_TIMEOUT=10s
NGINX_SEND_TIMEOUT=10s
NGINX_PROXY_READ_TIMEOUT=300s
NGINX_PROXY_SEND_TIMEOUT=300s
NGINX_CERT_RELOAD_INTERVAL_SECONDS=300

# Recommended for non-production environments
NGINX_ROBOTS_TAG=noindex, nofollow, noarchive

# API runtime configuration (same .env file)
NODE_ENV=production

# SCM provider
SCM_PROVIDER=github
SCM_TOKEN=replace_me
SCM_BOT_LOGIN=ai-pr-sentinel[bot]
# Production security controls for webhook ingress
# Comma-separated values are supported for multiple repositories.
# Example: darkneiss/ai-pr-sentinel,acme/tools-repo
SCM_WEBHOOK_ALLOWED_REPOSITORIES=owner/repository
SCM_WEBHOOK_STRICT_REPOSITORY_ALLOWLIST=true
SCM_WEBHOOK_REQUIRE_DELIVERY_ID=true
SCM_WEBHOOK_DELIVERY_TTL_SECONDS=86400
SCM_WEBHOOK_SECRET=replace_me
SCM_WEBHOOK_VERIFY_SIGNATURE=true

# Logging
LOG_LEVEL=info
LLM_LOG_RAW_RESPONSE=false

# AI triage
AI_TRIAGE_ENABLED=true
AI_TEMPERATURE=0.1
AI_LABEL_KIND_BUG=kind/bug
AI_LABEL_KIND_FEATURE=kind/feature
AI_LABEL_KIND_QUESTION=kind/question
AI_LABEL_DOCUMENTATION=documentation
AI_LABEL_HELP_WANTED=help wanted
AI_LABEL_GOOD_FIRST_ISSUE=good first issue
AI_LABEL_DOCUMENTATION_CONFIDENCE_THRESHOLD=0.9
AI_LABEL_HELP_WANTED_CONFIDENCE_THRESHOLD=0.9
AI_LABEL_GOOD_FIRST_ISSUE_CONFIDENCE_THRESHOLD=0.95
AI_CLASSIFICATION_CONFIDENCE_THRESHOLD=0.8
AI_SENTIMENT_CONFIDENCE_THRESHOLD=0.75
AI_DUPLICATE_SIMILARITY_THRESHOLD=0.85

# Provider selection and credentials
LLM_TIMEOUT=
LLM_PROVIDER=groq
LLM_API_KEY=replace_me
LLM_MODEL=openai/gpt-oss-20b
LLM_BASE_URL=https://api.groq.com/openai/v1/chat/completions

# LangSmith observability (optional)
LANGSMITH_TRACING=false
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=ai-pr-sentinel
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_WORKSPACE_ID=
