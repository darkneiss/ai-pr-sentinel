PORT=3000
APP_VERSION=1.0.0
GITHUB_TOKEN=your-github-token
GITHUB_BOT_LOGIN=ai-pr-sentinel[bot]
# Shared secret used to verify GitHub webhook signatures (must match GitHub Webhook "Secret").
# Behavior:
# - production: required (app fails fast if missing)
# - development: optional; if set, signature verification is enabled
GITHUB_WEBHOOK_SECRET=
# Optional override for advanced scenarios: true | false
# GITHUB_WEBHOOK_VERIFY_SIGNATURE=
NODE_ENV=development

# Logging: debug | info | warn | error
# Default: debug in non-production, info in production.
LOG_LEVEL=debug

# AI triage toggle
AI_TRIAGE_ENABLED=false

# Provider selection: openai | gemini | ollama
LLM_PROVIDER=ollama

# Generic LLM settings (applies to selected provider)
# Notes:
# - For OpenAI-compatible providers (OpenAI, Groq, etc.), the adapter calls:
#   {LLM_BASE_URL}/v1/chat/completions
# - Do NOT include "/v1/chat/completions" in LLM_BASE_URL.
# - Groq example:
#   LLM_PROVIDER=openai
#   LLM_BASE_URL=https://api.groq.com/openai
#   LLM_MODEL=openai/gpt-oss-20b
LLM_API_KEY=
LLM_MODEL=
LLM_BASE_URL=

# Provider-specific fallback values (used only if LLM_* is empty)
OPENAI_API_KEY=
GEMINI_API_KEY=
# OLLAMA_BASE_URL=http://127.0.0.1:11434
# OLLAMA_MODEL=llama3.1

# Optional provider-specific model/base URL overrides
# OpenAI
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_BASE_URL=https://api.openai.com
# Gemini
# GEMINI_MODEL=gemini-1.5-flash
# GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta
